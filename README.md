Deployed a small HDFS cluster to explore file partitioning, replication, and data recovery using Hadoop Distributed File System (HDFS). Uploaded large files with different replication settings and used the HDFS command line to manage file distribution. Implemented Python code with WebHDFS API to read files and recover data from a damaged node. Used PyArrow to read HDFS files and handle I/O operations efficiently. Simulated node failure and assessed how replication affects fault tolerance by analyzing block distribution. This project focused on space efficiency, fault tolerance, and data recovery in distributed systems
